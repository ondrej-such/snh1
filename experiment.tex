\section{Methodology.}

\subsection{Datasets}

It is natural to consider the benchmark datasets used in previous evaluation of coupling methods [\cite{wu2004probability}]. The authors considered altogether seven datasets with number of classes ranging from 3 to 26. For each dataset they extracted 40 pairs of training and testing datasets. Half of these were smaller (300 training samples and 500 testing samples) and the other half was larger (800 training samples and 1000 testing samples). In our experiments we use only the larger pairs. 

As a preliminary step we conducted analysis of linear separability of the datasets. We used ECOS solver in CVXR library to solve the underlying quadratic program. The results are reported in Table \ref{tab:sep}.

\input{tab-sep.tex}

We can infer that except for 'waveform' dataset, majority of binary problems are linearly separable.

\subsection{Classification methodology}

We have opted to use LDA as a binary classification tool. Its appeal is that it is applicable even for linearly separable datasets, thus obviating additional crossvalidation step incurred by methods that use regularization (e.g. penalized logistic regression or SVM). It usually provides results close to logistic regression [\cite{james2013introduction}].

For preprocessing we first removed features that were constant across classes. Then we projected the data using PCA to the subspace for which corresponding singular values were $> tol$, where $tol$ is a hyper-parameter of an experiment. We used PCA without scaling or centering since the datasets' features were already normalized to interval $[-1,1]$. 

For training LDA we used MASS library in R. We implemented coupling methods in C++ using Eigen library. As arguments to the coupling methods we use log-odds, i.e. instead of $r_{ij}$ they expect
$$
\tilde r_{ij} = \log \biggl(\frac{1}{r_{ji}} - 1\biggr).
$$
The resulting matrix $\tilde{\boldsymbol{R}}$ is skew symmetric (with the convention of having zeroes on the diagonal).

This parametrization allows for precise representation of extremely small probabilities which are sometimes produced by LDA. These small probabilities might be expected given that a large fraction of binary problems is linearly separable. 

Small probabilities generally have very little effect on the implementation of Bayes covariant methods which generally operate using log-odds. However small probabilities do affect both the method of Wu-Lin-Weng as well sa radial method, because then Assumption \ref{ass:1} fails to hold. 

%\begin{figure}[!ht]
%	\includegraphics[width = 0.5\linewidth]{graph/dna-lda.pdf}
%	\includegraphics[width = 0.5\linewidth]{graph/waveform-lda.pdf}
%	\caption{Projections of three-class datasets using LDA Left: dna, right: waveform}
%\end{figure}

\section{Experimental results.}

The choice of a coupling method is an important task for practitioners. We aim to help by posing the following interrelated questions 

\begin{itemize}
\item[a)] Which coupling methods without parameters show good performance across diverse data sets? Is it the orthodox method of Wu-Lin-Weng?
\item[b)] If the answer to a) is a coupling method which is not Bayes covariant, can we find a parametric Bayes covariant method which  matches its performance?
\item[c)] If the answer to b) is negative, is it better to apply the change of priors before or after coupling? Additionally, how serious is the impact of the lack of Bayes covariance in practice?
\end{itemize}

These questions will be put to test in Sections \ref{sec:exp1} --\ref{sec:exp4}.



\subsection{Experiment: Accuracy of canonical coupling methods} \label{sec:exp1}

The first experiment compares the performance the following canonical coupling methods
\begin{itemize}
\item method of Wu-Lin-Weng, which is widely used in software libraries, and thus can be viewed as an orthodox choice,
\item normal coupling, which is a Bayes covariant method,
\item radial coupling, which is not Bayes covariant,
\item Hinton's oracle.
\end{itemize}

% \input{tab-multi.tex}
The results are shown in Figure \ref{fig:exp1-plot1}. We can clearly see that Wu-Lin-Weng's method has the most robust performance. On some datasets it trounces normal coupling method by a wide margin. The edge over the radial method is smaller with only mnist and usps datasets showing a significant difference for smaller values of $tol$ hyperparameter.  However in view of Theorem \ref{thm:K3} the Wu-Lin-Weng's method is not Bayes covariant, therefore we will extend the set of Bayes covariant methods beyond the canonical normal coupling.

\begin{figure}
	\includegraphics{graphs/exp1-plot1.pdf}
	\caption{Success rate plotted against the logarithm of $tol$ hyper-parameter, evaluated for different datasets.}
	\label{fig:exp1-plot1}
\end{figure}

\subsection{Experiment: Accuracy of Bayes covariant methods without parameters}
 \label{sec:exp2}


In this experiment we compare  Bayes covariant coupling methods \emph{without} parameters that could match the performance of Wu-Lin-Weng's method. We investigate  the case of three class datasets. This is a natural starting point, since it is the smallest number of classes where the question is meaningful to ask. All experiments use value of 0.05 for $tol$ hyperparameter based on results of Section \ref{sec:exp1}.  In our comparison we include the normal method, as well as the three arboreal methods $ \boldsymbol{s}_1,~ \boldsymbol{s}_2,~ \boldsymbol{s}_3$ that are not canonical. We consider all possible triples of classes in all datasets. The resulting statistics are shown in Table \ref{tab:step2}. 

\input{tab-step2.tex}

We can see that in slightly less than half of the cases none of the four parameterless Bayes covariant methods was able to match the performance of Wu-Lin-Weng's method. This leads us to extend evaluation to Bayes covariant methods with parameters. 

\subsection{Experiment: A parametric family of Bayes covariant methods}
\label{sec:exp3}

Let us define two parameter family of Bayes covariant coupling methods
\begin{align}
a_1 \boldsymbol{s}_1 \oplus a_2 \boldsymbol{s}_2 \oplus a_3 \boldsymbol{s}_3,\quad\textrm{where } a_1 + a_2 +a_3 = 1. \label{eq:family}
\end{align}
Note that this family includes the normal coupling method \eqref{eq:normal3} as well as the three arboreal methods $\boldsymbol{s}_1, \boldsymbol{s}_2, \boldsymbol{s}_3$.

We start by selecting 1000 three class subsets from all datasets for problems where normal method was outperformed by Wu-Lin-Weng's method. For each three-class classification problem we will try to match the performance of Wu-Lin-Weng method with a Bayes covariant method in family \eqref{eq:family}.

Selecting parameters for methods in family \eqref{eq:family} requires several methodological choices. 
\begin{itemize}
\item To avoid bias in selection of parameters $a_1, a_2, a_3$ we use a subset of testing dataset to find their optimal values. As a result, we will be comparing the accuracy of Wu-Lin-Weng method evaluated with repeated five-fold cross-validation accuracy of a method in family \eqref{eq:family}. We use 20 repetitions.
\item To compare two parameter vectors, we compare their resulting cross-validation accuracy. An alternative approach would be to use  a gradient based optimization for a smooth proxy (e.g. cross-entropy) of empirical accuracy. We opted for the former because the problem is two-dimensional, and we can use grid search instead.
\item Our choice of grid search necessitates a selection of a compact subset of parameter space that will be sampled. We choose to examine points in the simplex defined by  $a_i\geq 0$, for $i=1,2,3$. As Table \ref{tab:step2} shows, this simplex contained in more than half case a Bayes covariant method matching the performance of Wu-Lin-Weng's method.
\end{itemize}


\begin{figure}[!ht]
\includegraphics{graphs/exp2-summary.pdf}
\caption{Comparison of success rate for parametric Bayes covariant methods \eqref{eq:family} vs. Wu-Lin-Weng's method}
\label{fig:par-bc}
\end{figure}

The summary statistics are shown in Figure \ref{fig:par-bc}.
We can see that only in minority of cases we found a parametric Bayes covariant coupling method matching the performance of Wu-Lin-Weng's method. 

%\subsection{Experiment: }
%
%We determined that among the 1000 three-class problems we have examined, the largest gap between Bayes-covariant parametric methods and Wu-Lin-Weng method occurred for mnist dataset and classes 5,6,9. Figure 
%
%\begin{itemize}
%	\item We searched within a much larger rectangle $D$ containing the simplex $a_i\geq 0$, which in this case is a triangle $T$.
%	\item We used Brier score as a smooth proxy for measuring the quality of multi-class classifier. This score is much smoother than 0-1 score which measures accuracy.
%\end{itemize}
%
%The results are shown in Figure \ref{fig:score}
%
%
%\begin{figure}[!ht]
%	\includegraphics{graphs/exp2-detail.pdf}
%	\caption{Color map indicates the value of Brier score computed for an ensemble of coupling methods on the testing dataset. The vertices triangle indicate the arboreal coupling methods, and the black circle the location of the optimum.}
%	\label{fig:score}
%\end{figure}
%
%We can see that indeed the optimum over the rectangle lies outside of the simplex. Let us compare the resulting accuracy of the optima in $\Delta$ and $D$. The results are shown in Table \ref{tab:step5}.
%
%\input tab-step5.tex

\subsection{Experiment: Effect of change of priors}  \label{sec:exp4}
%\subsection{Wu-Lin-Weng's method}

We have shown that are situations when Wu-Lin-Weng's method outperforms even the best Bayes-covariant parametric methods. In this section we thus ponder the question whether some non-Bayes covariant method would be more resilients to change of priors. We consider two facets to this question.

Let us start with some notation. Consider a classification method $\boldsymbol{c}_0$ based on coupling. Suppose the priors change, and let us denote by $\boldsymbol{c}_1$ the classification model where we apply \eqref{eq:changePrior} to binary classifiers, and by $\boldsymbol{c}_2$ the classification method when we apply \eqref{eq:changePrior} after coupling. 

The first question is whether for some coupling method the difference in predictions (we call it \emph{spread}) between $\boldsymbol{c}_1$ and $\boldsymbol{c}_2$ would be smaller. To gauge this question we apply change of priors by increasing tenfold the prior for every class in turn.  The averaged results are shown in Table \ref{tab:exp4}. 

\input {tab-exp4.tex}

The results, as expected, detect no change between $\boldsymbol{c}_1, \boldsymbol{c}_2$ for normal coupling method. However, there is no consistent difference in spread between radial and Wu-Lin-Weng's coupling method. Spread for the radial method is lower for 3 datasets (letter, mnist, usps datasets), higher for 3 datasets (dna, satimage, segment) and tied for waveform dataset.

The second question is whether a coupling method would more consistently provide true answers. Let us remark under Assumption 1 the Bayes classifier \emph{should} change prediction of any sample if the change of priors is sufficiently large. Thus to evaluate this question 

\begin{figure}[!ht]
	\includegraphics{exp4-truth.pdf}
	\caption{Difference in accuracies of $\boldsymbol{c}_2$ and $\boldsymbol{c}_1$ for radial and Wu-Lin-Weng's coupling method.}
	\label{fig:score}
\end{figure}
